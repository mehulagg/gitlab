---
stage: Create
group: Gitaly
info: To determine the technical writer assigned to the Stage/Group associated with this page, see https://about.gitlab.com/handbook/engineering/ux/technical-writing/#assignments
type: reference
---

# Pack-objects cache **(FREE SELF)**

[Gitaly](index.md), the service that provides storage for Git
repositories, can be configured to cache a short rolling window of Git
clone responses. This can reduce server load when your server receives
lots of CI clone traffic.

## Overview

The cache is implemented by wrapping `git pack-objects`, an internal
part of Git that gets invoked indirectly via the PostUploadPack and
SSHUploadPack Gitaly RPC's. When the cache is enabled, anything that
uses PostUploadPack or SSHUploadPack can benefit from it. It is
agnostic to the transport (HTTP or SSH), Git protocol version (v0 or
v2) and the type of clone (full clones, incremental fetches, shallow
clones, partial clones etc.).

The pack-objects cache is designed for CI clone traffic: it prevents
the situation where two or more `git pack-objects` processes run at
the same time with identical inputs. Other types of traffic may not
benefit as much, or not at all. For example, if you have a busy
repository that gets cloned a lot by users, then they will typically
clone all branches. Any time a branch changes the next clone would be
a cache miss.

The pack-objects cache is a local cache: it stores its metadata in
memory in the Gitaly process it is enabled in, and it stores the
actual Git data it is caching in files on local storage. Using local
files has the benefit that the operating system will automatically
keep parts of the pack-objects cache in RAM, making it more efficient.

Because the pack-objects cache can lead to a significant increase in
disk write IO it is off by default.

## Configuration

|Setting|Default|Description|
|:---|:---|:---|
|`enabled`|`false`|Turns on the cache. When off, Gitaly runs a dedicated `git pack-objects` process for each request.|
|`dir`|`<PATH TO FIRST STORAGE>/+gitaly/PackObjectsCache`|Local directory where cache files get stored.|
|`max_age`|`5m` (5 minutes)|Cache entries older than this get evicted and removed from disk.|

In `gitlab.rb`:

```ruby
gitaly['pack_objects_cache_enabled'] = true
# gitaly['pack_objects_cache_dir'] = '/var/opt/gitlab/git-data/repositories/+gitaly/PackObjectsCache'
# gitaly['pack_objects_cache_max_age'] = '5m'
```

### Cache storage directory `dir`

The cache needs a directory to store its data in. This directory
should be in a filesystem with enough space, on a disk with enough IO
bandwidth. The default choice is a subdirectory of the first Gitaly
storage defined in the config file.

- If the cache filesystem runs out of **space**, all clones will start **failing**
- If the cache disk runs out of **IO bandwidth**, all clones, and probably the entire server, will **slow down** 

It is allowed for multiple Gitaly processes to use the same directory
for cache storage. Each Gitaly processes uses a unique
random string as part of the cache filenames it creates so they will
not collide, nor will they re-use another process's files.

While the default is to use a subdirectory of the first repository
storage directory defined in the Gitaly configuration file, there is
no technical need for the cache to be on the same filesystem as the
repositories. We chose this default because the repository storage
filesystem is more likely to have enough space and IO bandwidth.

The amount of IO bandwidth required from the disk depends on the size
and shape of the repositories on your Gitaly server and on the kind of
traffic your users generate. You can use the network egress rate as an
estimate.

The amount of space required depends on the bytes per second that your
users pull from the cache and the size of the `max_age` cache eviction
window. If your users pull 100 MB/s and you use a 5 minute window,
then on average you will have `5*60*100MB = 30GB` of data in your
cache directory. This is an expected average, not a guarantee. Peak
size may exceed this average.

### Cache eviction window `max_age`

The `max_age` configuration setting lets us control how much data is
stored in the cache. Entries older than `max_age` get evicted from the
in-memory metadata store, and deleted from disk.

Note that this does not interfere with ongoing requests, so it is OK
for `max_age` to be less than the time it takes to do a clone over a
slow connection. This is because Unix filesystems do not truly delete
a file until all processes that are reading the deleted file have
closed it.

The default value of 5 minutes was chosen after a traffic analysis on
GitLab.com. For us it seemed to provide a good enough balance between
cache hit ratio and disk usage.

## Observability

### Logs

|Message|Fields|Description|
|:---|:---|:---|
|`generated bytes`|`bytes`, `cache_key`|Logged when an entry was added to the cache|
|`served bytes`|`bytes`, `cache_key`|Logged when an entry was read from the cache|

In case of a cache miss, Gitaly will log both a `generated bytes` and
a `served bytes` message. In case of a cache hit, there is only a
`served bytes` message.

Example:

```
{
  "bytes":26186490,
  "cache_key":"1b586a2698ca93c2529962e85cda5eea8f0f2b0036592615718898368b462e19",
  "correlation_id":"01F1MY8JXC3FZN14JBG1H42G9F",
  "grpc.meta.deadline_type":"none",
  "grpc.method":"PackObjectsHook",
  "grpc.request.fullMethod":"/gitaly.HookService/PackObjectsHook",
  "grpc.request.glProjectPath":"root/gitlab-workhorse",
  "grpc.request.glRepository":"project-2",
  "grpc.request.repoPath":"@hashed/d4/73/d4735e3a265e16eee03f59718b9b5d03019c07d8b6c51f90da3a666eec13ab35.git",
  "grpc.request.repoStorage":"default",
  "grpc.request.topLevelGroup":"@hashed",
  "grpc.service":"gitaly.HookService",
  "grpc.start_time":"2021-03-25T14:57:52.747Z",
  "level":"info",
  "msg":"generated bytes",
  "peer.address":"@",
  "pid":20961,
  "span.kind":"server",
  "system":"grpc",
  "time":"2021-03-25T14:57:53.543Z"
}
{
  "bytes":26186490,
  "cache_key":"1b586a2698ca93c2529962e85cda5eea8f0f2b0036592615718898368b462e19",
  "correlation_id":"01F1MY8JXC3FZN14JBG1H42G9F",
  "grpc.meta.deadline_type":"none",
  "grpc.method":"PackObjectsHook",
  "grpc.request.fullMethod":"/gitaly.HookService/PackObjectsHook",
  "grpc.request.glProjectPath":"root/gitlab-workhorse",
  "grpc.request.glRepository":"project-2",
  "grpc.request.repoPath":"@hashed/d4/73/d4735e3a265e16eee03f59718b9b5d03019c07d8b6c51f90da3a666eec13ab35.git",
  "grpc.request.repoStorage":"default",
  "grpc.request.topLevelGroup":"@hashed",
  "grpc.service":"gitaly.HookService",
  "grpc.start_time":"2021-03-25T14:57:52.747Z",
  "level":"info",
  "msg":"served bytes",
  "peer.address":"@",
  "pid":20961,
  "span.kind":"server",
  "system":"grpc",
  "time":"2021-03-25T14:57:53.543Z"
}
```

### Metrics

|Metric|Type|Lables|Description|
|:---|:---|:---|:---|
|`gitaly_pack_objects_cache_enabled`|gauge|`dir`,`max_age`|Set to `1` when the cache is enabled via the Gitaly config file|
|`gitaly_pack_objects_cache_lookups_total`|counter|`result`|Hit/miss counter for cache lookups|
|`gitaly_pack_objects_generated_bytes_total`|counter||Number of bytes written into the cache|
|`gitaly_pack_objects_served_bytes_total`|counter||Number of bytes read from the cache|
|`gitaly_streamcache_filestore_disk_usage_bytes`|gauge|`dir`|Total size of cache files|
|`gitaly_streamcache_index_entries`|gauge|`dir`|Number of entries in the cache|

Some of these metrics start with `gitaly_streamcache`
because they are generated by the "streamcache" internal library
package in Gitaly.

Example:

```
gitaly_pack_objects_cache_enabled{dir="/var/opt/gitlab/git-data/repositories/+gitaly/PackObjectsCache",max_age="300"} 1
gitaly_pack_objects_cache_lookups_total{result="hit"} 2
gitaly_pack_objects_cache_lookups_total{result="miss"} 1
gitaly_pack_objects_generated_bytes_total 2.618649e+07
gitaly_pack_objects_served_bytes_total 7.855947e+07
gitaly_streamcache_filestore_disk_usage_bytes{dir="/var/opt/gitlab/git-data/repositories/+gitaly/PackObjectsCache"} 2.6200152e+07
gitaly_streamcache_filestore_removed_total{dir="/var/opt/gitlab/git-data/repositories/+gitaly/PackObjectsCache"} 1
gitaly_streamcache_index_entries{dir="/var/opt/gitlab/git-data/repositories/+gitaly/PackObjectsCache"} 1
```

## Design notes

We designed this cache to solve a specific problem on GitLab.com: high
Gitaly server load due to massively parallel CI clones. Where
possible, we kept things as simple as possible, as long as the end
result would be adequate for GitLab.com.

### Streaming and backpressure

One of the main goals was to have both **streaming** and
**backpressure**. By "streaming" we mean that a consumer of a cache
entry can start reading and stream back data before the producer is
done writing the entry. We wanted this because Git clones are
relatively slow and we did not want to add to the end-to-end latency.
By "backpressure" we mean that the producer of a cache entry writes
bytes to disk no faster than the fastest consumer of the entry is
reading them. This has two benefits. First of all, if the consumer
hangs up, the producer gets a write error and also stops. This way we
don't write data to disk that no-one will look at. Second of all, we
get a natural limit on how much IO bandwidth we use. On its own, the
producer can write data faster than the consumers can read it. If
there was no backpressure, the producer would put excessive write IO
pressure on the cache storage disk.

### Storage considerations

Early on in the project we thought we would use object storage to
store the cache data but we later decided not to, for several reasons.

1. Object storage introduces a new point of failure
1. Local storage gets a boost from the operating system's page cache; there is no page cache for object storage

To support the second point: during testing on a server with high
cache throughput, where the number of bytes read from the cache peaks
over 100MB/s once an hour, we see disk reads at near 0 bytes per
second, with peaks of less than 1MB. This is possible because the
operating system is able to serve all the pack-objects cace reads from
the page cache, i.e. from RAM. This server does use a lot of IO
bandwidth, but that is all due to cache writes, not reads. With object
storage we would not get this extra layer of RAM caching from the
operating system.

### Off by default

While experimenting we found that in some cases the pack-objects cache
can use an unusually large amount of IO bandwidth. While our
infrastructure on GitLab.com is able to handle this, it did not seem
realistic to us to assume that this applies to all other GitLab
installations out there.

To give an example, look at the graph below, which ranks Gitaly
servers on GitLab.com by the number of bytes written to disk per
second. We are interested in the `file-praefect-*` servers because
they were involved in the experiment and they host a repository that
puts a lot of pressure on the cache. Note how before we enabled the
cache, the busiest `file-praefect-*` server ranked fourth, and how all
servers write less than 10 MB/s to disk.

![Disk writes before cache](img/pack-objects-writes-before.png)

Now look at this picture which shows data over the same window but one
week later, with the pack-objects cache enabled on the
`file-praefect-*` servers. Note how `file-praefect-01` is now the top
writer at 63MB/s, ahead of the number two who is below 20MB/s, and how
most of the other servers are still sitting below 10MB/s.

![Disk writes before cache](img/pack-objects-writes-after.png)

It seemed unreasonable to us to force such a (potential) jump in
resource consumption on all GitLab installations. This should be an
opt-in, not an opt-out.
